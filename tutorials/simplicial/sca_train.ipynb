{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Simplicial Complex Autoencoder (SCA)\n",
    "\n",
    "\n",
    "ðŸŸ¥ $\\quad m_{y \\rightarrow \\{z\\} \\rightarrow x}^{(r \\rightarrow r' \\rightarrow r)}  = M(h_{x}^{t, (r)}, h_{y}^{t, (r)}, att(h_{x}^{t, (r)}, h_{y}^{t, (r)}), x, y, \\Theta^t) \\qquad \\text{where } r'' < r < r'$\n",
    "\n",
    "ðŸŸ¥ $\\quad m_{y \\rightarrow \\{z\\} \\rightarrow x}^{(r' \\rightarrow r)} = M(h_{x}^{t, (r)}, h_{y}^{t, (r')}, att(h_{x}^{t, (r)}, h_{y}^{t, (r')}), x, y, \\Theta^t)$\n",
    "\n",
    "ðŸŸ§ $\\quad m_x^{(r \\rightarrow r' \\rightarrow r)}  = \\text{AGG}\\_{y \\in \\mathcal{L}\\_\\uparrow(x)} m_{y \\rightarrow \\{z\\} \\rightarrow x}^{(r \\rightarrow r' \\rightarrow r)}$\n",
    "\n",
    "ðŸŸ§ $\\quad m_x^{(r' \\rightarrow r)} = \\text{AGG}\\_{y \\in \\mathcal{C}(x)} m_{y \\rightarrow \\{z\\} \\rightarrow x}^{(r' \\rightarrow r)}$\n",
    "\n",
    "ðŸŸ© $\\quad m_x^{(r)}  = \\text{AGG}\\_{\\mathcal{N}\\_k \\in \\mathcal{N}}(m_x^{(k)})$\n",
    "\n",
    "ðŸŸ¦ $\\quad h_{x}^{t+1, (r)} = U(h_x^{t, (r)}, m_{x}^{(r)})$\n",
    "\n",
    "Where the notations are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from toponetx import SimplicialComplex\n",
    "import toponetx.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from topomodelx.nn.simplicial.sca_layer import SCALayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPUs are available we will make use of them. Otherwise, we will use CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import data ##\n",
    "\n",
    "The first step is to import the dataset, shrec16, a benchmark dataset for 3D mesh classification. We then lift each graph into our domain of choice, a simplicial complex.\n",
    "\n",
    "We also retrieve:\n",
    "- input signals `x_0`, `x_1`, and `x_2` on the nodes (0-cells), edges (1-cells), and faces (2-cells) for each complex: these will be the model's inputs,\n",
    "- a scalar classification label `y` associated to the cell complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shrec 16 small dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "shrec, _ = datasets.mesh.shrec_16(size=\"small\")\n",
    "\n",
    "shrec = {key: np.array(value) for key, value in shrec.items()}\n",
    "x_0s = shrec[\"node_feat\"]\n",
    "x_1s = shrec[\"edge_feat\"]\n",
    "x_2s = shrec[\"face_feat\"]\n",
    "\n",
    "ys = shrec[\"label\"]\n",
    "scs = shrec[\"complexes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 6th simplicial complex has 252 nodes with features of dimension 6.\n",
      "The 6th simplicial complex has 750 edges with features of dimension 10.\n",
      "The 6th simplicial complex has 500 faces with features of dimension 7.\n"
     ]
    }
   ],
   "source": [
    "i_complex = 6\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_0s[i_complex].shape[0]} nodes with features of dimension {x_0s[i_complex].shape[1]}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_1s[i_complex].shape[0]} edges with features of dimension {x_1s[i_complex].shape[1]}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_2s[i_complex].shape[0]} faces with features of dimension {x_2s[i_complex].shape[1]}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the inputs to test each message passing scheme:\n",
    "\n",
    "#### Adjacency Message Passing Scheme (AMPS):\n",
    "This will require features from the faces and edges outputting features on faces. The first neighborhood matrix will be the level 1 upper Laplacian, $L_{\\uparrow, 1}$, and the second neighborhood matrix will be the incidence matrix of the faces, $B_2$.\n",
    "\n",
    "#### Coadjacency Message Passing Scheme (CMPS):\n",
    "This will require features from faces, and edges again, but outputs features on the edges. The first neighborhood matrix will be the level 2 lower Laplacian, $L_{\\downarrow, 2}$, and the second neighborhood matrix will be the transpose of the incidence matrix of the faces, $B_{2}^T$.\n",
    "\n",
    "#### Homology and Cohomology Message Passing Scheme (HCMPS):\n",
    "This will require features from faces, edges, and nodes outputing features on the edges. The first neighborhood matrix will be the transpose of the incidence matrix of the edges, $B_{1}^T$, and the second neighborhood matrix will be the incidence matrix of the faces, $B_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_lap1_list = []\n",
    "down_lap2_list = []\n",
    "incidence1_t_list = []\n",
    "incidence2_list = []\n",
    "incidence2_t_list = []\n",
    "\n",
    "for sc in scs:\n",
    "    up_lap1 = sc.up_laplacian_matrix(rank=1)\n",
    "    down_lap2 = sc.down_laplacian_matrix(rank=2)\n",
    "    incidence1_t = sc.incidence_matrix(rank=1).T\n",
    "    incidence_2 = sc.incidence_matrix(rank=2)\n",
    "    incidence_2_t = sc.incidence_matrix(rank=2).T\n",
    "    up_lap1 = torch.from_numpy(up_lap1.todense()).to_sparse()\n",
    "    down_lap2 = torch.from_numpy(down_lap2.todense()).to_sparse()\n",
    "    incidence1_t = torch.from_numpy(incidence1_t.todense()).to_sparse()\n",
    "    incidence_2 = torch.from_numpy(incidence_2.todense()).to_sparse()\n",
    "    incidence_2_t = torch.from_numpy(incidence_2_t.todense()).to_sparse()\n",
    "\n",
    "    up_lap1_list.append(up_lap1)\n",
    "    down_lap2_list.append(down_lap2)\n",
    "    incidence1_t_list.append(incidence1_t)\n",
    "    incidence2_list.append(incidence_2)\n",
    "    incidence2_t_list.append(incidence_2_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neural Networks\n",
    "\n",
    "Using the SCALayer class, we create a neural network with stacked layers for each scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMPS\n",
    "in_channels_1a = x_1s.shape[-1]\n",
    "in_channels_2a = x_2s.shape[-1]\n",
    "out_channels_a = x_2s.shape[-1]\n",
    "\n",
    "# CMPS\n",
    "in_channels_1c = x_1s.shape[-1]\n",
    "in_channels_2c = x_2s.shape[-1]\n",
    "out_channels_c = x_1s.shape[-1]\n",
    "\n",
    "# HCMPS\n",
    "in_channels_1h = x_0s.shape[-1]\n",
    "in_channels_2h = x_2s.shape[-1]\n",
    "out_channels_h = x_1s.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMPSSCA(torch.nn.Module):\n",
    "    \"\"\"SCA with AMPS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels_1 : int\n",
    "        Dimension of input features on edges.\n",
    "    in_channels_2 : int\n",
    "        Dimension of input features on faces.\n",
    "    num_classes : int\n",
    "        Number of classes.\n",
    "    att : bool\n",
    "        Whether to use attention.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels_1,\n",
    "        in_channels_2,\n",
    "        num_classes,\n",
    "        att=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sca_layer = SCALayer(in_channels_1, in_channels_2, in_channels_2, att)\n",
    "        self.lin_ = torch.nn.Linear(in_channels_2, num_classes)\n",
    "\n",
    "    def forward(self, x_1, x_2, neighborhood_1, neighborhood_2):\n",
    "        \"\"\"Forward computation through layers, then linear layers, then avg pooling.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_0 : torch.Tensor, shape = [n_nodes, in_channels_0]\n",
    "            Input features on the nodes (0-cells).\n",
    "        x_1 : torch.Tensor, shape = [n_edges, in_channels_1]\n",
    "            Input features on the edges (1-cells).\n",
    "        neighborhood_0_to_0 : tensor, shape = [n_nodes, n_nodes]\n",
    "            Adjacency matrix of rank 0 (up).\n",
    "        neighborhood_1_to_2 : tensor, shape = [n_faces, n_edges]\n",
    "            Transpose of boundary matrix of rank 2.\n",
    "        x_2 : torch.Tensor, shape = [n_faces, in_channels_2]\n",
    "            Input features on the faces (2-cells).\n",
    "            Optional. Use for attention mechanism between edges and faces.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        _ : tensor, shape = [1]\n",
    "            Label assigned to whole complex.\n",
    "        \"\"\"\n",
    "        x_2 = self.sca_layer(x_1, x_2, neighborhood_1, neighborhood_2)\n",
    "        x_2 = self.lin_(x_2)\n",
    "        return torch.softmax(x_2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dim = max(ys)\n",
    "y_list = []\n",
    "\n",
    "for y in ys:\n",
    "    y_one_hot = torch.zeros(1, out_dim)\n",
    "    y_one_hot[0, y-1] = 1\n",
    "    y_list.append(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "x_0_train, x_0_test = train_test_split(x_0s, test_size=test_size, shuffle=False)\n",
    "x_1_train, x_1_test = train_test_split(x_1s, test_size=test_size, shuffle=False)\n",
    "x_2_train, x_2_test = train_test_split(x_2s, test_size=test_size, shuffle=False)\n",
    "\n",
    "up_lap1_train, up_lap1_test = train_test_split(\n",
    "    up_lap1_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "down_lap2_train, down_lap2_test = train_test_split(\n",
    "    down_lap2_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "incidence1_t_train, incidence1_t_test = train_test_split(\n",
    "    incidence1_t_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "incidence2_train, incidence2_test = train_test_split(\n",
    "    incidence2_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "incidence2_t_train, incidence2_t_test = train_test_split(\n",
    "    incidence2_t_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "y_train, y_test = train_test_split(y_list, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AMPSSCA(in_channels_1a, in_channels_2a, num_classes=out_dim)\n",
    "model = model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajbre\\AppData\\Local\\Temp\\ipykernel_37328\\2560640927.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y).float().to(device),\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (750) to match target batch_size (1).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     18\u001b[0m y_hat \u001b[39m=\u001b[39m model(x_1, x_2, up_lap1, incidence_2)\n\u001b[1;32m---> 19\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_hat, y)\n\u001b[0;32m     20\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     21\u001b[0m opt\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\ajbre\\anaconda3\\envs\\topoenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ajbre\\anaconda3\\envs\\topoenv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32mc:\\Users\\ajbre\\anaconda3\\envs\\topoenv\\Lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (750) to match target batch_size (1)."
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "num_epochs = 4\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for x_1, x_2, up_lap1, incidence_2, y in zip(\n",
    "        x_1_train, x_2_train, up_lap1_train, incidence2_train, y_train\n",
    "    ):\n",
    "        x_1, x_2, y = (\n",
    "            torch.tensor(x_1).float().to(device),\n",
    "            torch.tensor(x_2).float().to(device),\n",
    "            torch.tensor(y).float().to(device),\n",
    "        )\n",
    "        up_lap1, incidence_2 = up_lap1.float().to(\n",
    "            device\n",
    "        ), incidence_2.float().to(device)\n",
    "        opt.zero_grad()\n",
    "        y_hat = model(x_1, x_2, up_lap1, incidence_2)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            for x_1, x_2, up_lap1, incidence_2, y in zip(\n",
    "                x_1_test, x_2_test, up_lap1_test, incidence2_test, y_test\n",
    "            ):\n",
    "                x_1, x_2, y = (\n",
    "                    torch.tensor(x_1).float().to(device),\n",
    "                    torch.tensor(x_2).float().to(device),\n",
    "                    torch.tensor(y).float().to(device),\n",
    "                )\n",
    "                up_lap1, incidence_2 = up_lap1.float().to(\n",
    "                    device\n",
    "                ), incidence_2.float().to(device)\n",
    "                y_hat = model(x_1, x_2, up_lap1, incidence_2)\n",
    "                test_loss = loss_fn(y_hat, y)\n",
    "            print(f\"Test_loss: {test_loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4278, 0.1538, 0.6280,  ..., 1.7742, 1.5595, 0.8965],\n",
       "        [0.4095, 0.1731, 0.7004,  ..., 2.9332, 1.6330, 0.6524],\n",
       "        [1.2717, 0.1721, 0.4799,  ..., 2.5734, 1.5595, 1.1941],\n",
       "        ...,\n",
       "        [0.8114, 0.1777, 0.8643,  ..., 1.7053, 0.7571, 1.4963],\n",
       "        [0.4296, 0.2196, 1.1156,  ..., 1.8233, 2.0773, 0.6180],\n",
       "        [0.8864, 0.2132, 0.5716,  ..., 2.3777, 1.4339, 2.0468]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
